name: inverse
layout: true
class: center, middle, inverse
---
#CUDA, OpenCL and the GPGPU Revolution

$a{res:/bosatsu/data/snippets/qualifications.txt}
---
layout: false
.left-column[
  ## Agenda
]
.right-column[
- Introduction

- CUDA

- OpenCL

- Getting Started

]

---
name: CUDA-OPENCL-Introduction
class: center, middle, inverse
# Introduction

---
background-image: url(/bosatsu/data/images/gpgpu/moore.jpg)
class: center, middle

.footnote[https://newsroom.intel.com/editorials/moores-law-setting-the-record-straight/]


---
class: center, middle, inverse

.quotation[What Andy giveth, Bill taketh away...]

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/freelunch-02.png">

.footnote[https://herbsutter.com/welcome-to-the-jungle/]

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/freelunch-00.png">

.footnote[http://www.gotw.ca/publications/concurrency-ddj.htm]

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/freelunch-01.png">

.footnote[https://herbsutter.com/welcome-to-the-jungle/]

---
class: center, middle

<img height="400" src="/bosatsu/data/images/gpgpu/freelunch-03.png">

.footnote[https://herbsutter.com/welcome-to-the-jungle/]

---
class: center, middle

<img style="height:450px;" src="/bosatsu/data/images/gpgpu/freelunch-05.png">

.footnote[https://herbsutter.com/welcome-to-the-jungle/]

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/freelunch-04.png">

.footnote[https://herbsutter.com/welcome-to-the-jungle/]





---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/edge-00.jpg">

.footnote[https://www.energomonitor.com/insight/edge-computing-fog-computing-benefits-of-fogging/]

---
class: center, middle, inverse

.quotation[Mainstream hardware is becoming permanently parallel, heterogeneous, and distributed. These changes are permanent, and so will permanently affect the way we have to write performance-intensive code on mainstream architectures.]
.quotation-source[https://herbsutter.com/welcome-to-the-jungle/]

---
class: center, middle, inverse

.quotation[The GPU is being leaned on more heavily than it ever has before. With the right algorithm, you can get 10 times the performance per watt with a GPU on machine learning than you can with a CPU.]
.quotation-source[Patrick Moorhead, https://www.wired.com/2017/04/apples-making-gpu-control-destiny/]

---
name: CUDA-OPENCL-CUDA
class: center, middle, inverse
# CUDA

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/cuda-architecture.png">

.quotation-source["Professional CUDA C Programming"]



---
```cpp
#include <stdio.h>

__global__ void helloFromGPU(void)
{
    printf("Hello, World from the GPU!\n");
}

int main(void)
{
  printf("Hello, World from the CPU!\n");

  helloFromGPU <<<1, 10>>>();
  cudaDeviceReset();
  return 0;
}
```

---
```cpp
#include <stdio.h>

*__global__ void helloFromGPU(void)
{
    printf("Hello, World from the GPU!\n");
}

int main(void)
{
  printf("Hello, World from the CPU!\n");

  helloFromGPU <<<1, 10>>>();
  cudaDeviceReset();
  return 0;
}
```

---
```cpp
#include <stdio.h>

__global__ void helloFromGPU(void)
{
    printf("Hello, World from the GPU!\n");
}

int main(void)
{
  printf("Hello, World from the CPU!\n");

* helloFromGPU <<<1, 10>>>();
  cudaDeviceReset();
  return 0;
}
```

---
class: center, middle

```cpp
  helloFromGPU <<<1, 10>>>();
```

<img src="/bosatsu/data/images/gpgpu/block-grid-01.png">

---
```bash
$ nvcc helloworld.cu -o helloworld
```
--
```bash
$ ./helloworld
Hello, World from the CPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
Hello, World from the GPU!
```

---
class: center, middle

```cpp
  helloFromGPU <<<2, 8>>>();
```

<img src="/bosatsu/data/images/gpgpu/block-grid-02.png">

---

# CUDA Program Structure

1. Allocate GPU memory

--
2. Copy data from CPU memory to GPU memory

--
3. Invoke the CUDA kernel

--
4. Copy data from GPU memory to CPU memory

--
5. Free GPU memory

---

# Kernel Rules

1. Only access device memory

--
2. void return type

--
3. Fixed argument list

--
4. No static variables

--
5. No function pointers

--
6. Asychronous

---
```cpp
void sumArraysOnHost(float *A,
                     float *B,
                     float *C,
                     const int N)
{
  for( int idx = 0; idx < N; idx++ ) {
    C[idx] = A[idx] + B[idx];
  }
}
```

--
```cpp
__global__ void sumArraysOnGPU(float *A,
                               float *B,
                               float *C)
{
*  int i = threadIdx.x;
  C[i] = A[i] + B[i];
}
```

---
```cpp
int main(int argc, char **argv) {
   int dev = 0;
   cudaSetDevice(dev);

   int nElem = 32;

   size_t nBytes = nElem * sizeof(float);

   float *h_A, *h_b, *hostRef, *gpuRef;
   h_A = (float *) malloc(nBytes);
   h_B = (float *) malloc(nBytes);
   gpuRef = (float *) malloc(nBytes);
   ...
}
```

---
```cpp
   ...
   initialData(h_A, nElem);
   initialData(h_B, nElem);

   memset(gpuRef, 0, nBytes);

   float *d_A, *d_B, *d_c;
   cudaMalloc((float **) &d_A, nBytes);
   cudaMalloc((float **) &d_B, nBytes);
   cudaMalloc((float **) &d_C, nBytes);

   cudaMemcpy(d_A, h_A, nBytes,
     cudaMemcpyHostToDevice);
   cudaMemcpy(d_B, h_B, nBytes,
     cudaMemcpyHostToDevice);

   ...
```

---
```cpp
   ...
   dim3 block (nElem);
   dim3 grid (nElem/block.x);

   sumArraysOnGPU<<< grid, block >>>
      (d_A, d_B, d_C);

   cudaMemcpy(gpuRef, d_C, nBytes,
     cudaMemcpyDeviceToHost);

   cudaFree(d_A);
   cudaFree(d_B);
   cudaFree(d_C);

   free(h_A);
   free(h_B);
   free(gpuRef);

   return(0);
}
```



---
name: CUDA-OPENCL-OPENCL
class: center, middle, inverse
# OpenCL

---
class: center, middle, inverse

.quotation[Traditionally, when evaluating hardware platforms for acceleration, one must inevitably consider the trade-off between flexibility and performance.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[On one end of the spectrum, general purpose processors (GPP) provide a high degree of flexibility and ease of use, but perform relatively inefficiently. These platforms tend to be more readily accessible, can be produced cheaply, and are appropriate for a wide variety of uses and reuses.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[On the other end of the spectrum, application specific integrated circuits (ASIC) provide high performance at the cost of being inflexible and more difficult to produce. These circuits are dedicated to a specific application, and are expensive and time consuming to produce.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[FPGAs serve as a compromise between these two extremes. They belong to a more general class of programmable logic devices (PLD) and are, in the most simple sense, a reconfigurable integrated circuit. As such, they provide the performance benefits of integrated circuits, with the reconfigurable flexibility of GPPs.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
# CPUs vs GPUs vs FPGAs vs ASICs

--
## Bitcoin mining

--
* High-end CPU might get you 20,000,000 H/s

--
 * Several hundred thousand years to find a solution

--
* GPUs can get you 200,000,000 H/s

--
 * Hundreds of years to find a solution

--
* Run them in parallel, but they generate heat and are more optimized for floating point numbers

--
* Availability of a Verilog design for Bitcoin mining offered FPGA solutions

--
 * Better use of transistors, ran cooler, good at bit twiddling

--
 * Offered 1,000,000,000 H/s

--
 * Chaining 100 of these would allow you to find a solution... in 100 years

--
* Application-specific integrated circuits (ASICs)

---
class: center, middle

<img style="height: 400px;" src="/bosatsu/data/images/blockchain/bitfury.png"/>

.footnote[Marco Krohn]

---
# Von Neumann Architecture

.center[.middle[<img style="height: 400px;" src="/bosatsu/data/images/gpgpu/von-neumann.png">]]

.center[.footnote[https://en.wikipedia.org/wiki/Von_Neumann_architecture]]

---
class: center, middle, inverse

.quotation[In comparison, the programmable logic cells on FPGAs can be used to implement the data and control path found in common logic functions, which do not rely on the Von Neumann architecture. They are also capable of exploiting distributed on-chip memory, as well as large degrees of pipeline parallelism, which fit naturally with the feed-forward nature deep learning methods.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[Modern FPGAs also support partial dynamic reconfiguration, where part of the FPGA can be reprogrammed while another part of the FPGA is being used. This can have implications for large deep learning models, where individual layers could be reconfigured on the FPGA while not disrupting ongoing computation in other layers.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[With GPUs and other fixed architectures, a software execution model is followed, and structured around executing tasks in parallel on independent compute units. As such, the goal in developing deep learning techniques for GPUs is to adapt algorithms to follow this model, where computation is done in parallel, and data interdependence is ensured.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[In contrast, FPGA architecture is tailored for the application. When developing deep learning techniques for FPGAs, there is less emphasis on adapting algorithms for a fixed computational structure, allowing more freedom to explore algorithm level optimizations.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle, inverse

.quotation[Techniques which require many complex low-level hardware control operations which cannot be easily implemented in high-level software languages are especially attractive for FPGA implementations.]
.quotation-source["Deep Learning on FPGAs: Past, Present, and Future", Lacey et al.]

---
class: center, middle

<img height="500" src="/bosatsu/data/images/gpgpu/opencl-logo.png">

---
# OpenCL Support

--
* GPPs

--
* GPUs

--
* DSPs

--
* FPGAs

---
class: center, middle

<img height="400" src="/bosatsu/data/images/gpgpu/metal.png">

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/vulkan.png">

---
class: center, middle

<iframe width="560" height="315" src="https://www.youtube.com/embed/rvCD9FaTKCA" frameborder="0" allowfullscreen></iframe>

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/spir.png">

---
class: center, middle

<img height="400" src="/bosatsu/data/images/gpgpu/opencl-2017.jpg">

.quotation-source["Khronos Group, IWOCL 2017"]

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/webgpu.png">

---
class: center, middle

<img height="400" src="/bosatsu/data/images/gpgpu/webgl2.png">


---
name: CUDA-OPENCL-STARTED
class: center, middle, inverse
# Getting Started

---
# The Beast

<video height="400px" loop="true" autoplay="true" src="https://d1vhcvzji58n1j.cloudfront.net/assets/products/bonw12/360-7dabd8187b.mp4"/>

.footnote[https://system76.com/laptops/bonobo]

---
class: center, middle
# AWS GPU Instances

<img height="500" src="/bosatsu/data/images/gpgpu/aws-gpu.png">

---
class: center, middle
# Apple eGPU Developer Kit

<img height="500" src="/bosatsu/data/images/gpgpu/apple-egpu.png">


---
name: CUDA-OPENCL-BOOKS
class: center, middle, inverse
# Books

---
class: center, middle

<img src="/bosatsu/data/images/gpgpu/cuda-book-00.jpg">

---
class: center, middle

<img style="height: 400px;" src="/bosatsu/data/images/gpgpu/cuda-book-01.jpg">


---
class: center, middle

<img style="height: 400px;" src="/bosatsu/data/images/gpgpu/cuda-book-02.jpg">

---
class: center, middle

<img style="height: 400px;" src="/bosatsu/data/images/gpgpu/opencl-book-00.png">


$a{res:/bosatsu/data/snippets/questions.txt}
